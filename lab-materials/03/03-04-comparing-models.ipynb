{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad2cc4e-31ec-4648-b0fe-6632f2bdbc36",
   "metadata": {},
   "source": [
    "## Comparing models for our different tasks\n",
    "\n",
    "In this Notebook, we are going to use another model, Flan-T5-Small in parallel to Mistral-7B and see how it behaves.\n",
    "\n",
    "Flan-T5-Small is indeed much smaller, runs without GPU and on only 1GB of RAM, but is it up to the task?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4e2b81-0e10-4390-a7b8-5ddfda53a3e3",
   "metadata": {},
   "source": [
    "### Requirements and Imports\n",
    "\n",
    "If you have selected the right workbench image to launch as per the Lab's instructions, you should already have all the needed libraries. If not uncomment the first line in the next cell to install all the right packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c595d-967e-47de-a598-02b5d1ccec85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import VLLMOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from certs import prepare_certs\n",
    "from tgis_client import TgisClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c428fbad-2345-4536-b687-72416d6b9b15",
   "metadata": {},
   "source": [
    "### Langchain pipeline\n",
    "\n",
    "We are now going to define two different LLM endpoints, and two different pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f95a70-89fb-4e21-a51c-24e862b7953e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mistral_inference_server_url = \"REPLACE_ME\"\n",
    "\n",
    "prepare_certs(mistral_inference_server_url)\n",
    "llm = VLLMOpenAI(\n",
    "    openai_api_key=\"EMPTY\",\n",
    "    openai_api_base= f\"{mistral_inference_server_url}/v1\",\n",
    "    model_name=\"/mnt/models/\",\n",
    "    max_tokens=512,\n",
    "    top_p=0.95,\n",
    "    temperature=0.01,\n",
    "    presence_penalty=1.03,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de69dfa2-5d95-43e7-82fa-2bde24800e47",
   "metadata": {},
   "source": [
    "Flan-t5-small client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782046b7-f0a4-487c-86fc-3131e668c6c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flan_t5_inference_url = 'REPLACE_ME'\n",
    "flan_t5_model_id = 'flan-t5-tgis'\n",
    "\n",
    "flan_t5_client = TgisClient(flan_t5_inference_url, model_id=flan_t5_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b950bc-4d73-49e5-a35b-083a784edd50",
   "metadata": {},
   "source": [
    "The **template** will be the same for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb7517-faa2-43ed-a95d-835de975f916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"<s>[INST]\n",
    "You are a helpful, respectful and honest assistant.\n",
    "Always assist with care, respect, and truth. Respond with utmost utility yet securely.\n",
    "Avoid harmful, unethical, prejudiced, or negative content. Ensure replies promote fairness and positivity.\n",
    "I will give you a text, then ask a question about it. Give a precise and as concise as possible answer to this question.\n",
    "\n",
    "### TEXT:\n",
    "{text}\n",
    "\n",
    "### QUESTION:\n",
    "{query}\n",
    "\n",
    "### ANSWER:\n",
    "[/INST]\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"input\"], template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbe2119-2128-4432-aed1-126e9c8c034f",
   "metadata": {},
   "source": [
    "And we can now create two **conversation** objects that we will use to query the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d9f32-d4ae-4c2f-b513-d520413d2cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation = LLMChain(llm=llm, prompt=PROMPT, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849fbd67-220c-4a02-8e4e-7e0d1aa91588",
   "metadata": {},
   "source": [
    "We are now ready to query the models!\n",
    "\n",
    "In this example, we are only going to query one claim and see what happens. Of course, feel free to try with different ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86a78a-ac3b-42a3-921c-a16fdbecbedd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_input = '''I hope this email finds you well. My name is Sarah Turner, and I am writing to file a claim for a recent car accident that occurred on January 2nd, 2024, at approximately 3:30 PM. My policy number is AC-987654321.\n",
    "\n",
    "The accident took place at the intersection of Birch Street and Willow Avenue in the city of Evergreen. I was driving my vehicle, a black Toyota Camry with license plate number DEF-456, heading south on Birch Street. At the intersection, the traffic signal was green, and I proceeded through the intersection.\n",
    "\n",
    "At the same time, another vehicle, a blue Chevrolet Traverse with license plate number GHI-789, was traveling west on Willow Avenue. Unfortunately, the driver failed to stop at the red traffic signal, resulting in a collision with the front passenger side of my vehicle.\n",
    "\n",
    "The impact caused significant damage to both vehicles. The front bumper and right headlight of my Toyota Camry are extensively damaged, and there are also damages to the front driver's side of the Chevrolet Traverse. Fortunately, no injuries were sustained during the accident, and both drivers were able to move their vehicles to the side of the road.\n",
    "\n",
    "I promptly exchanged information with the other driver, Mr. Daniel Reynolds, including our names, phone numbers, insurance details, and a brief description of the accident. Additionally, I took photos of the accident scene, including the damages to both vehicles and the position of the traffic signal.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1105a8-af3c-4bbf-b7d6-d055d754d53d",
   "metadata": {},
   "source": [
    "Analyze the claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a072a3-f0c9-498d-a171-44bfbcbc1dcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment_query = \"What is the sentiment of the person sending this claim?\"\n",
    "location_query = \"Where does the event the claim is related to happen?\"\n",
    "time_query = \"When does the event the claim is related to happen? If possible, specify the date and the time.\"\n",
    "\n",
    "print(\"***************************\")\n",
    "print(\"Original content:\")\n",
    "print(\"-----------------\")\n",
    "print(text_input)\n",
    "print(\"\\n\\n                          ----====----\\n\")\n",
    "\n",
    "print('Analysis with Mistral-7B:')\n",
    "print(\"--------\")\n",
    "print(f\"- Sentiment: \")\n",
    "conversation.predict(text=text_input, query=sentiment_query);\n",
    "print(\"\\n- Location: \")\n",
    "conversation.predict(text=text_input, query=location_query);\n",
    "print(\"\\n- Time: \")\n",
    "conversation.predict(text=text_input, query=time_query);\n",
    "print(\"\\n\\n                          ----====----\\n\")\n",
    "\n",
    "print('Analysis with Flan-T5-Small:')\n",
    "print(\"--------\")\n",
    "print(f\"- Sentiment: \")\n",
    "print(flan_t5_client.predict(text=text_input, query=sentiment_query))\n",
    "print(\"\\n- Location: \")\n",
    "print(flan_t5_client.predict(text=text_input, query=location_query))\n",
    "print(\"\\n- Time: \")\n",
    "print(flan_t5_client.predict(text=text_input, query=time_query))\n",
    "print(\"\\n\\n                          ----====----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e28a5b0-6c93-42ba-84dd-42e17746d11d",
   "metadata": {},
   "source": [
    "As you can see, Flan-T5-Small is much faster. After all, it's an 80 Million parameters model only. It seems to work to some extent, but the results are nowhere near the ones from Mistral-7B, which is a 7 Billion parameter.\n",
    "\n",
    "The art of working with LLM is to find the right balance between the performance and accuracy you require, and the resources it takes along with the involved costs.\n",
    "\n",
    "Therefore it's important to have sanity checks in place to make sure that as you data changes, or your model evolves, you always get the behaviour you expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
